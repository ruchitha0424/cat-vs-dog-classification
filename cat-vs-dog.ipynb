{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf55931-68f4-427e-b314-810cdda02d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a81c62-3805-4459-ab29-b9e9c32b1cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"dataset/train\"\n",
    "\n",
    "cat_dir = os.path.join(base_dir, \"Cat\")\n",
    "dog_dir = os.path.join(base_dir, \"Dog\")\n",
    "\n",
    "print(\"Number of cat images:\", len(os.listdir(cat_dir)))\n",
    "print(\"Number of dog images:\", len(os.listdir(dog_dir)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160bb9b1-63f3-4f89-b8c5-fe9abf03ff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "cat_images = os.listdir(cat_dir)\n",
    "dog_images = os.listdir(dog_dir)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    img = Image.open(os.path.join(cat_dir, random.choice(cat_images)))\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Cat\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(2, 5, i + 6)\n",
    "    img = Image.open(os.path.join(dog_dir, random.choice(dog_images)))\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Dog\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7279ca11-4191-4590-8c18-cd09bf10c2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height, img_width = 150, 150\n",
    "batch_size = 32\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e95e25-bf16-4d85-8d74-fd48a8ef308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ece9c8-5c31-474f-9767-89dd0a1b5ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426bec46-9bb9-4783-b183-e7ae21c7519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0527e4f-9480-4f1e-9e5a-6992175c16dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def predict_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "    prediction = model.predict(img_array)\n",
    "    class_name = \"Dog\" if prediction[0][0] > 0.5 else \"Cat\"\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Prediction: {class_name}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb4dd03-fade-4af9-a881-bb5f5c771fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_image(\"dataset/train/Cat/1000.jpg\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0f1dd7-4e65-4e04-b372-d5d56d653ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def predict_and_save_to_csv(image_paths, output_csv=\"predictions.csv\"):\n",
    "    results = []\n",
    "\n",
    "    for img_path in image_paths:\n",
    "        img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "        prediction = model.predict(img_array)\n",
    "        predicted_label = \"Dog\" if prediction[0][0] > 0.5 else \"Cat\"\n",
    "\n",
    "        results.append({\n",
    "            \"filename\": os.path.basename(img_path),\n",
    "            \"prediction\": predicted_label\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Predictions saved to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c49b95-ccd7-4a02-bfd2-266b79a747c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "dog_image_paths = glob.glob(\"dataset/train/Dog/*.jpg\")  \n",
    "predict_and_save_to_csv(dog_image_paths, output_csv=\"predictions.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5b66a4-b81f-4ded-b75a-11785b095073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
